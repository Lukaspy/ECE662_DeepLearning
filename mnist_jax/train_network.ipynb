{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e87da48c",
   "metadata": {},
   "source": [
    "# Train the Network\n",
    "This notebook demonstrates how to use the Network class with different activation functions from jax.nn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a06aa1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "# Import Network and JAX libraries\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "jnp.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "from loader import load_data, load_data_onehot\n",
    "from network import Network, init_network_params, cross_entropy_loss, mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c8f0b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test data using loader.py\n",
    "# Use loader.load_data_onehot for one-hot encoded labels.\n",
    "train_iter, test_iter = load_data_onehot(flatten=True)\n",
    "X_train, Y_train = next(train_iter)\n",
    "X_test, Y_test = next(test_iter)\n",
    "\n",
    "# Define network architecture\n",
    "layer_sizes = [784, 30, 10]    # Gets 97% with mse loss\n",
    "# layer_sizes = [784, 30, 10]\n",
    "key = jax.random.PRNGKey(0)\n",
    "net = Network(layer_sizes, loss_fn=mse_loss, activation=jax.nn.swish)\n",
    "init_params = init_network_params(layer_sizes, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a94a3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(2.3408, dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Untrained performance\n",
    "# jnp.sum(jax.vmap(net.evaluate, in_axes=(None, 0, 0))(init_params, X_test, Y_test)) / X_test.shape[0]\n",
    "jnp.mean(jax.vmap(cross_entropy_loss, in_axes=(None, 0, 0, None))(init_params, X_test, Y_test, net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d774ee18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(2.3026, dtype=float32, weak_type=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Untrained expected cross-entropy\n",
    "-jnp.log(1/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d4268e",
   "metadata": {},
   "source": [
    "## Test differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11bb31df",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = net.backward(init_params, X_train[2], Y_train[2])\n",
    "aval, adiff = jax.value_and_grad(mse_loss, argnums=0)(init_params, X_train[2], Y_train[2], net)\n",
    "hval, hdiff = h[1], h[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92e07992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': [Array(True, dtype=bool),\n",
       "  Array(True, dtype=bool),\n",
       "  Array(True, dtype=bool)],\n",
       " 'w': [Array(True, dtype=bool),\n",
       "  Array(True, dtype=bool),\n",
       "  Array(True, dtype=bool)]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree.map(lambda x, y: jnp.allclose(x, y), hdiff, adiff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa21de1",
   "metadata": {},
   "source": [
    "## Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4728795f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2469, Train Acc: 92.55%, Test Acc: 92.77%\n",
      "Epoch 2, Loss: 0.1801, Train Acc: 94.65%, Test Acc: 94.17%\n",
      "Epoch 3, Loss: 0.1438, Train Acc: 95.80%, Test Acc: 95.23%\n",
      "Epoch 4, Loss: 0.1175, Train Acc: 96.58%, Test Acc: 95.82%\n",
      "Epoch 5, Loss: 0.0998, Train Acc: 97.14%, Test Acc: 96.08%\n",
      "Epoch 6, Loss: 0.0898, Train Acc: 97.42%, Test Acc: 96.00%\n",
      "Epoch 7, Loss: 0.0817, Train Acc: 97.65%, Test Acc: 96.23%\n",
      "Epoch 8, Loss: 0.0742, Train Acc: 97.83%, Test Acc: 96.34%\n",
      "Epoch 9, Loss: 0.0679, Train Acc: 98.02%, Test Acc: 96.40%\n",
      "Epoch 10, Loss: 0.0626, Train Acc: 98.19%, Test Acc: 96.46%\n",
      "Epoch 11, Loss: 0.0580, Train Acc: 98.30%, Test Acc: 96.55%\n",
      "Epoch 12, Loss: 0.0539, Train Acc: 98.42%, Test Acc: 96.60%\n",
      "Epoch 13, Loss: 0.0503, Train Acc: 98.53%, Test Acc: 96.61%\n",
      "Epoch 14, Loss: 0.0472, Train Acc: 98.60%, Test Acc: 96.62%\n",
      "Epoch 15, Loss: 0.0444, Train Acc: 98.69%, Test Acc: 96.65%\n",
      "Epoch 16, Loss: 0.0418, Train Acc: 98.77%, Test Acc: 96.59%\n",
      "Epoch 17, Loss: 0.0395, Train Acc: 98.87%, Test Acc: 96.55%\n",
      "Epoch 18, Loss: 0.0374, Train Acc: 98.93%, Test Acc: 96.57%\n",
      "Epoch 19, Loss: 0.0356, Train Acc: 98.97%, Test Acc: 96.55%\n",
      "Epoch 20, Loss: 0.0340, Train Acc: 99.03%, Test Acc: 96.55%\n",
      "Epoch 21, Loss: 0.0325, Train Acc: 99.08%, Test Acc: 96.56%\n",
      "Epoch 22, Loss: 0.0311, Train Acc: 99.11%, Test Acc: 96.48%\n",
      "Epoch 23, Loss: 0.0297, Train Acc: 99.14%, Test Acc: 96.52%\n",
      "Epoch 24, Loss: 0.0283, Train Acc: 99.16%, Test Acc: 96.49%\n",
      "Epoch 25, Loss: 0.0270, Train Acc: 99.20%, Test Acc: 96.48%\n",
      "Epoch 26, Loss: 0.0256, Train Acc: 99.23%, Test Acc: 96.47%\n",
      "Epoch 27, Loss: 0.0243, Train Acc: 99.26%, Test Acc: 96.49%\n",
      "Epoch 28, Loss: 0.0230, Train Acc: 99.31%, Test Acc: 96.47%\n",
      "Epoch 29, Loss: 0.0216, Train Acc: 99.36%, Test Acc: 96.45%\n",
      "Epoch 30, Loss: 0.0203, Train Acc: 99.42%, Test Acc: 96.42%\n",
      "Epoch 31, Loss: 0.0190, Train Acc: 99.45%, Test Acc: 96.43%\n",
      "Epoch 32, Loss: 0.0178, Train Acc: 99.50%, Test Acc: 96.47%\n",
      "Epoch 33, Loss: 0.0167, Train Acc: 99.53%, Test Acc: 96.49%\n",
      "Epoch 34, Loss: 0.0157, Train Acc: 99.58%, Test Acc: 96.45%\n",
      "Epoch 35, Loss: 0.0147, Train Acc: 99.61%, Test Acc: 96.50%\n",
      "Epoch 36, Loss: 0.0138, Train Acc: 99.65%, Test Acc: 96.47%\n",
      "Epoch 37, Loss: 0.0130, Train Acc: 99.68%, Test Acc: 96.50%\n",
      "Epoch 38, Loss: 0.0122, Train Acc: 99.70%, Test Acc: 96.54%\n",
      "Epoch 39, Loss: 0.0116, Train Acc: 99.72%, Test Acc: 96.54%\n",
      "Epoch 40, Loss: 0.0109, Train Acc: 99.74%, Test Acc: 96.56%\n",
      "Epoch 41, Loss: 0.0104, Train Acc: 99.76%, Test Acc: 96.55%\n",
      "Epoch 42, Loss: 0.0099, Train Acc: 99.78%, Test Acc: 96.60%\n",
      "Epoch 43, Loss: 0.0094, Train Acc: 99.79%, Test Acc: 96.64%\n",
      "Epoch 44, Loss: 0.0089, Train Acc: 99.82%, Test Acc: 96.63%\n",
      "Epoch 45, Loss: 0.0085, Train Acc: 99.84%, Test Acc: 96.63%\n",
      "Epoch 46, Loss: 0.0081, Train Acc: 99.86%, Test Acc: 96.62%\n",
      "Epoch 47, Loss: 0.0077, Train Acc: 99.86%, Test Acc: 96.61%\n",
      "Epoch 48, Loss: 0.0073, Train Acc: 99.86%, Test Acc: 96.58%\n",
      "Epoch 49, Loss: 0.0070, Train Acc: 99.87%, Test Acc: 96.58%\n",
      "Epoch 50, Loss: 0.0067, Train Acc: 99.89%, Test Acc: 96.57%\n",
      "Epoch 51, Loss: 0.0064, Train Acc: 99.89%, Test Acc: 96.55%\n",
      "Epoch 52, Loss: 0.0061, Train Acc: 99.90%, Test Acc: 96.54%\n",
      "Epoch 53, Loss: 0.0058, Train Acc: 99.90%, Test Acc: 96.56%\n",
      "Epoch 54, Loss: 0.0056, Train Acc: 99.90%, Test Acc: 96.56%\n",
      "Epoch 55, Loss: 0.0054, Train Acc: 99.91%, Test Acc: 96.57%\n",
      "Epoch 56, Loss: 0.0051, Train Acc: 99.91%, Test Acc: 96.57%\n",
      "Epoch 57, Loss: 0.0049, Train Acc: 99.92%, Test Acc: 96.58%\n",
      "Epoch 58, Loss: 0.0048, Train Acc: 99.93%, Test Acc: 96.59%\n",
      "Epoch 59, Loss: 0.0046, Train Acc: 99.94%, Test Acc: 96.59%\n",
      "Epoch 60, Loss: 0.0044, Train Acc: 99.94%, Test Acc: 96.59%\n",
      "Epoch 61, Loss: 0.0043, Train Acc: 99.94%, Test Acc: 96.59%\n",
      "Epoch 62, Loss: 0.0041, Train Acc: 99.95%, Test Acc: 96.61%\n",
      "Epoch 63, Loss: 0.0040, Train Acc: 99.95%, Test Acc: 96.60%\n",
      "Epoch 64, Loss: 0.0039, Train Acc: 99.96%, Test Acc: 96.61%\n",
      "Epoch 65, Loss: 0.0038, Train Acc: 99.96%, Test Acc: 96.60%\n",
      "Epoch 66, Loss: 0.0036, Train Acc: 99.96%, Test Acc: 96.60%\n",
      "Epoch 67, Loss: 0.0035, Train Acc: 99.96%, Test Acc: 96.60%\n",
      "Epoch 68, Loss: 0.0034, Train Acc: 99.96%, Test Acc: 96.60%\n",
      "Epoch 69, Loss: 0.0033, Train Acc: 99.96%, Test Acc: 96.60%\n",
      "Epoch 70, Loss: 0.0033, Train Acc: 99.96%, Test Acc: 96.61%\n",
      "Epoch 71, Loss: 0.0032, Train Acc: 99.96%, Test Acc: 96.61%\n",
      "Epoch 72, Loss: 0.0031, Train Acc: 99.96%, Test Acc: 96.60%\n",
      "Epoch 73, Loss: 0.0030, Train Acc: 99.96%, Test Acc: 96.61%\n",
      "Epoch 74, Loss: 0.0030, Train Acc: 99.97%, Test Acc: 96.61%\n",
      "Epoch 75, Loss: 0.0029, Train Acc: 99.97%, Test Acc: 96.61%\n",
      "Epoch 76, Loss: 0.0028, Train Acc: 99.97%, Test Acc: 96.61%\n",
      "Epoch 77, Loss: 0.0028, Train Acc: 99.97%, Test Acc: 96.62%\n",
      "Epoch 78, Loss: 0.0027, Train Acc: 99.97%, Test Acc: 96.62%\n",
      "Epoch 79, Loss: 0.0026, Train Acc: 99.97%, Test Acc: 96.62%\n",
      "Epoch 80, Loss: 0.0026, Train Acc: 99.97%, Test Acc: 96.62%\n",
      "Epoch 81, Loss: 0.0025, Train Acc: 99.97%, Test Acc: 96.61%\n",
      "Epoch 82, Loss: 0.0025, Train Acc: 99.97%, Test Acc: 96.62%\n",
      "Epoch 83, Loss: 0.0024, Train Acc: 99.97%, Test Acc: 96.64%\n",
      "Epoch 84, Loss: 0.0024, Train Acc: 99.97%, Test Acc: 96.64%\n",
      "Epoch 85, Loss: 0.0024, Train Acc: 99.97%, Test Acc: 96.64%\n",
      "Epoch 86, Loss: 0.0023, Train Acc: 99.97%, Test Acc: 96.61%\n",
      "Epoch 87, Loss: 0.0023, Train Acc: 99.97%, Test Acc: 96.61%\n",
      "Epoch 88, Loss: 0.0022, Train Acc: 99.97%, Test Acc: 96.62%\n",
      "Epoch 89, Loss: 0.0022, Train Acc: 99.97%, Test Acc: 96.60%\n",
      "Epoch 90, Loss: 0.0022, Train Acc: 99.97%, Test Acc: 96.61%\n",
      "Epoch 91, Loss: 0.0021, Train Acc: 99.97%, Test Acc: 96.62%\n",
      "Epoch 92, Loss: 0.0021, Train Acc: 99.97%, Test Acc: 96.62%\n",
      "Epoch 93, Loss: 0.0021, Train Acc: 99.97%, Test Acc: 96.62%\n",
      "Epoch 94, Loss: 0.0020, Train Acc: 99.97%, Test Acc: 96.62%\n",
      "Epoch 95, Loss: 0.0020, Train Acc: 99.97%, Test Acc: 96.62%\n",
      "Epoch 96, Loss: 0.0020, Train Acc: 99.97%, Test Acc: 96.62%\n",
      "Epoch 97, Loss: 0.0019, Train Acc: 99.97%, Test Acc: 96.62%\n",
      "Epoch 98, Loss: 0.0019, Train Acc: 99.97%, Test Acc: 96.62%\n",
      "Epoch 99, Loss: 0.0019, Train Acc: 99.97%, Test Acc: 96.61%\n",
      "Epoch 100, Loss: 0.0019, Train Acc: 99.97%, Test Acc: 96.62%\n"
     ]
    }
   ],
   "source": [
    "params = net.sgd(init_params, X_train, Y_train, X_test, Y_test, batch_size=128, lr=3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10386c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgd = partial(net.sgd, X=X_train, Y=Y_train, X_test=X_test, Y_test=Y_test, \n",
    "#               batch_size=128, lr=1.0)\n",
    "# jit_sgd = partial(jax.jit, static_argnames=(\"epochs\",))(sgd)\n",
    "# n_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f93c5548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = sgd(init_params, epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3120955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = jit_sgd(init_params, epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e4f0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
