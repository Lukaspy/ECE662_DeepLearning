{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffd4a365",
   "metadata": {},
   "source": [
    "# Training an Equinox MLP on Spiral Data\n",
    "\n",
    "This notebook demonstrates how to train a three-layer MLP (using Equinox) to classify the spiral dataset generated by `spiral_data.py`. The training loop uses JAX and Equinox, and the model is compiled with `eqx.filter_jit` for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2ed19b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "import matplotlib.pyplot as plt\n",
    "from spiral_data import generate_spiral_data\n",
    "from mlp import MLP\n",
    "\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06e131c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'jaxlib.mlir._mlir_libs._mlir._Globals' object has no attribute 'register_traceback_file_exclusion'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Generate spiral dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m X, y = \u001b[43mgenerate_spiral_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints_per_class\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m num_classes = \u001b[32m3\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# One-hot encode labels\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/college/deeplearning/hw3/spiral_data.py:15\u001b[39m, in \u001b[36mgenerate_spiral_data\u001b[39m\u001b[34m(points_per_class, num_classes, noise, random_seed)\u001b[39m\n\u001b[32m     13\u001b[39m     X[ix] = np.c_[r * np.cos(t), r * np.sin(t)]\n\u001b[32m     14\u001b[39m     y[ix] = class_number\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, jnp.array(y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/college/deeplearning/.venv/lib/python3.13/site-packages/jax/_src/numpy/array_constructors.py:268\u001b[39m, in \u001b[36marray\u001b[39m\u001b[34m(object, dtype, copy, order, ndmin, device)\u001b[39m\n\u001b[32m    266\u001b[39m   # TODO(jakevdp): update this once we support NumPy 2.0 semantics for the copy arg.\n\u001b[32m    267\u001b[39m   out = np.array(object) if copy else np.asarray(object)\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m else:\n\u001b[32m    269\u001b[39m   raise TypeError(f\"Unexpected input type for array: {type(object)}\")\n\u001b[32m    270\u001b[39m out_array: Array = lax._convert_element_type(\n\u001b[32m    271\u001b[39m     out, dtype, weak_type=weak_type, sharding=sharding)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/college/deeplearning/.venv/lib/python3.13/site-packages/jax/_src/lax/lax.py:1725\u001b[39m, in \u001b[36m_convert_element_type\u001b[39m\u001b[34m(operand, new_dtype, weak_type, sharding, warn_on_complex_to_real_cast)\u001b[39m\n\u001b[32m   1718\u001b[39m   operand = literals.LiteralArray(np.asarray(operand).astype(new_dtype),\n\u001b[32m   1719\u001b[39m                                        weak_type)\n\u001b[32m   1720\u001b[39m elif (\n\u001b[32m   1721\u001b[39m     isinstance(operand, np.ndarray) and operand.dtype != dtypes.float0\n\u001b[32m   1722\u001b[39m     and new_dtype != dtypes.float0\n\u001b[32m   1723\u001b[39m ):\n\u001b[32m   1724\u001b[39m   try:\n\u001b[32m-> \u001b[39m\u001b[32m1725\u001b[39m     # If the value is a literal, we convert it to a LiteralArray to avoid\n\u001b[32m   1726\u001b[39m     # any canonicalization of it as a NumPy array. We may as well just do the\n\u001b[32m   1727\u001b[39m     # conversion while we are here.\n\u001b[32m   1728\u001b[39m     operand = literals.LiteralArray(\n\u001b[32m   1729\u001b[39m         np.asarray(operand).astype(new_dtype), weak_type\n\u001b[32m   1730\u001b[39m     )\n\u001b[32m   1731\u001b[39m   except TypeError:\n\u001b[32m   1732\u001b[39m     # Not every dtype we know about has a NumPy cast defined, e.g., for some\n\u001b[32m   1733\u001b[39m     # combinations of ml_dtypes types.\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/college/deeplearning/.venv/lib/python3.13/site-packages/jax/_src/core.py:612\u001b[39m, in \u001b[36mbind\u001b[39m\u001b[34m(self, *args, **params)\u001b[39m\n\u001b[32m    611\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPrimitive\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m612\u001b[39m   name: \u001b[38;5;28mstr\u001b[39m\n\u001b[32m    613\u001b[39m   \u001b[38;5;66;03m# set for multi-output primitives.\u001b[39;00m\n\u001b[32m    614\u001b[39m   multiple_results: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/college/deeplearning/.venv/lib/python3.13/site-packages/jax/_src/core.py:628\u001b[39m, in \u001b[36m_true_bind\u001b[39m\u001b[34m(self, *args, **params)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/college/deeplearning/.venv/lib/python3.13/site-packages/jax/_src/lax/lax.py:4934\u001b[39m, in \u001b[36m_convert_element_type_bind_with_trace\u001b[39m\u001b[34m(trace, args, params)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/college/deeplearning/.venv/lib/python3.13/site-packages/jax/_src/core.py:638\u001b[39m, in \u001b[36mbind_with_trace\u001b[39m\u001b[34m(self, trace, args, params)\u001b[39m\n\u001b[32m    636\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_true_bind\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **params):\n\u001b[32m    637\u001b[39m   \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args:\n\u001b[32m--> \u001b[39m\u001b[32m638\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, Tracer) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m arg._trace.is_valid():\n\u001b[32m    639\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m escaped_tracer_error(arg)\n\u001b[32m    640\u001b[39m   \u001b[38;5;66;03m# TODO: figure out how to handle function arguments for this assert\u001b[39;00m\n\u001b[32m    641\u001b[39m   \u001b[38;5;66;03m# assert (not config.enable_checks.value or\u001b[39;00m\n\u001b[32m    642\u001b[39m   \u001b[38;5;66;03m#         all(isinstance(arg, Tracer) or valid_jaxtype(arg) for arg in args)), args\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m   \u001b[38;5;66;03m# is called frequently and it's slightly faster to avoid using a context\u001b[39;00m\n\u001b[32m    646\u001b[39m   \u001b[38;5;66;03m# manager object.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/college/deeplearning/.venv/lib/python3.13/site-packages/jax/_src/core.py:1162\u001b[39m, in \u001b[36mprocess_primitive\u001b[39m\u001b[34m(self, primitive, args, params)\u001b[39m\n\u001b[32m   1161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34munsafe_buffer_pointer\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1162\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ConcretizationTypeError(\u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1163\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe unsafe_buffer_pointer() method was called on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._error_repr()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1164\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._origin_msg()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/college/deeplearning/.venv/lib/python3.13/site-packages/jax/_src/dispatch.py:90\u001b[39m, in \u001b[36mapply_primitive\u001b[39m\u001b[34m(prim, *args, **params)\u001b[39m\n\u001b[32m     88\u001b[39m prev = lib.jax_jit.swap_thread_local_state_disable_jit(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m   outs = \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     92\u001b[39m   lib.jax_jit.swap_thread_local_state_disable_jit(prev)\n",
      "    \u001b[31m[... skipping hidden 12 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/college/deeplearning/.venv/lib/python3.13/site-packages/jax/_src/lazy_loader.py:46\u001b[39m, in \u001b[36mattach.<locals>.__getattr__\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m) -> Any:\n\u001b[32m     45\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m submodules:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     value = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpackage_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m     \u001b[38;5;66;03m# Update module-level globals to avoid calling ``__getattr__`` again\u001b[39;00m\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# for this ``name``.\u001b[39;00m\n\u001b[32m     49\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(sys.modules[owner_name], name, value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/importlib/__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     86\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1331\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:935\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1026\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:488\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/college/deeplearning/.venv/lib/python3.13/site-packages/jaxlib/mlir/dialects/mhlo.py:19\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[33;03m\"\"\"MLIR Dialect for mhlo operations.\"\"\"\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# pylint: disable=wildcard-import,relative-beyond-top-level,g-import-not-at-top\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_mhlo_ops_gen\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_mlir_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_mlirHlo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/college/deeplearning/.venv/lib/python3.13/site-packages/jaxlib/mlir/dialects/_mhlo_ops_gen.py:13\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_ods_common\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      6\u001b[39m     equally_sized_accessor \u001b[38;5;28;01mas\u001b[39;00m _ods_equally_sized_accessor,\n\u001b[32m      7\u001b[39m     get_default_loc_context \u001b[38;5;28;01mas\u001b[39;00m _ods_get_default_loc_context,\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m     segmented_accessor \u001b[38;5;28;01mas\u001b[39;00m _ods_segmented_accessor,\n\u001b[32m     11\u001b[39m )\n\u001b[32m     12\u001b[39m _ods_ir = _ods_cext.ir\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43m_ods_cext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mglobals\u001b[49m\u001b[43m.\u001b[49m\u001b[43mregister_traceback_file_exclusion\u001b[49m(\u001b[34m__file__\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbuiltins\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequence \u001b[38;5;28;01mas\u001b[39;00m _Sequence, Union \u001b[38;5;28;01mas\u001b[39;00m _Union\n",
      "\u001b[31mAttributeError\u001b[39m: 'jaxlib.mlir._mlir_libs._mlir._Globals' object has no attribute 'register_traceback_file_exclusion'"
     ]
    }
   ],
   "source": [
    "# Generate spiral dataset\n",
    "X, y = generate_spiral_data(points_per_class=100, num_classes=3, noise=0.2)\n",
    "num_classes = 3\n",
    "# One-hot encode labels\n",
    "Y = jax.nn.one_hot(y, num_classes)\n",
    "print(f\"X shape: {X.shape}, Y shape: {Y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14461aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and accuracy metric\n",
    "\n",
    "def compute_loss(model, x, y):\n",
    "    \"\"\"Complete this function to return the cross-entropy loss.\"\"\" \n",
    "    pred_y = jax.vmap(model)(x)  # vectorise the model over a batch of data\n",
    "    return - y * jax.numpy.log(pred_y)\n",
    "\n",
    "\n",
    "def compute_accuracy(model, x, y):\n",
    "    \"\"\"Complete this function to return the accuracy.\"\"\"\n",
    "    pred_y = jax.vmap(model)(x)\n",
    "    pred_y = jnp.argmax(pred_y, axis=1)\n",
    "    return jnp.mean(y == pred_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f331e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training step (JIT compiled)\n",
    "@eqx.filter_jit\n",
    "def train_step(model, x, y, opt_state, optimizer):\n",
    "    def loss_fn(model):\n",
    "        return compute_loss(model, x, y)\n",
    "    loss, grads = eqx.filter_value_and_grad(loss_fn)(model)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state, eqx.filter(model, eqx.is_array))\n",
    "    model = eqx.apply_updates(model, updates)\n",
    "    return model, opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa027ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and optimizer\n",
    "key = jax.random.PRNGKey(0)\n",
    "model = MLP() # Instantiate your MLP model here\n",
    "optimizer = optax.adam(learning_rate=) # Choose your optimizer and learning_rate.\n",
    "opt_state = optimizer.init(eqx.filter(model, eqx.is_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b29d508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = # Set the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model, opt_state = train_step(model, X, Y, opt_state, optimizer)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        loss = compute_loss(model, X, Y)\n",
    "        acc = compute_accuracy(model, X, Y)\n",
    "        print(f\"Epoch {epoch+1}: Loss={loss:.4f}, Accuracy={acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44695eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize decision boundaries and predictions\n",
    "h = 0.01\n",
    "x_min, x_max = float(jnp.min(X[:, 0])) - 0.5, float(jnp.max(X[:, 0])) + 0.5\n",
    "y_min, y_max = float(jnp.min(X[:, 1])) - 0.5, float(jnp.max(X[:, 1])) + 0.5\n",
    "xx, yy = jnp.meshgrid(jnp.arange(x_min, x_max, h), jnp.arange(y_min, y_max, h))\n",
    "grid = jnp.c_[xx.ravel(), yy.ravel()]\n",
    "logits = jax.vmap(model)(grid)\n",
    "preds = jnp.argmax(logits, axis=1)\n",
    "preds = preds.reshape(xx.shape)\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.contourf(xx, yy, preds, alpha=0.3, cmap=plt.cm.rainbow)\n",
    "for class_number in range(num_classes):\n",
    "    plt.scatter(X[y == class_number, 0], X[y == class_number, 1], label=f\"Class {class_number}\", edgecolor='k')\n",
    "plt.legend()\n",
    "plt.title(\"MLP Decision Boundaries on Spiral Data\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.axis(\"equal\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8639ff1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
